---
layout: post
title: "Learning Deep Features for Discriminative Localization"
description: "Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba (CVPR 2016)"
date: 2020-09-22
categories: paper
tags: [review, deeplearning, image localization]
image: 
---

# [1] 아이디어 제안 배경

## Global Average Pooling (GAP)

GAP는 [Network in Network](https://arxiv.org/abs/1312.4400) 논문에서 소개된 pooling 방법론입니다. Convolutional feature map의 평균을 취해 하나의 값으로 변경하기 때문에 이와 같은 이름이 붙었습니다. 주된 역할은 기존의 fully connected layer를 대체하는 것입니다. CNN 기반의 분류모델에서 결과값을 도출하기 위해서는 마지막 convolutional layer를 flatten한 후 fc layer의 입력으로 넣는 방식을 사용했습니다. 그러나 fc layer는 많은 파라미터를 필요로 하고, 오버피팅의 위험이 높아 dropout 등에 의지해야 하는 문제점이 있었습니다. Network in Network 논문에서 GAP는 파라미터를 거의 차지하지 않으며 그 자체로서 구조적인 regularizer 역할을 하여 오버피팅을 막는다고 언급합니다.


## Object Localization

이미지가 특정 클래스에 속할 때, 그 클래스에 해당하는 객체의 위치를 표시하는 task가 있습니다. 이를 Object Localization이라 합니다. 하나의 객체를 대상으로 한다는 점과, 객체에 해당하는 좌표(Bounding Box)가 결과물로 나온다는 점이 특징입니다.

### Weakly Supervised Object Localization
Weakly Supervised Learning은 Segmentation Mask나 Bounding Box 등 상대적으로 비용이 많이 드는 레이블을 사용하는 방법(Fully Supervised) 대신, 구하기 쉬운 레이블만을 사용하여 해당 task를 해결하는 방법론을 말합니다. 본 논문에서 다루는 Object Localization을 예로 들면, Bounding Box 대신 Class label만을 사용하여 Localization을 수행하는 것을 뜻합니다. 구하기 쉬운 레이블 정보를 사용하면서도 성능을 유지하는 것이 해당 방법론의 목표입니다. 


 본 논문이 등장하기 전까지의 방법론에서 꼽을 수 있는 문제점은 다음과 같습니다. 
- End-to-end로 학습할 수 없음
- 여러 번의 forward pass를 수행해야 함
- CNN 기반의 localization은 fc layer의 이전까지의 feature map에 대해서만 가능

그나마 가장 유사했던 선행연구는 Global Max Pooling(GMP)를 이용하였는데, 의미있는 region의 한 부분만 활성화하기 때문에 GAP에 비해서 object를 전체적으로 파악하는 데 한계가 있음을 지적합니다. 논문에서는 실험을 통해 classification task에서는 유사한 성능을 기록하지만, localization에서는 GAP의 성능이 더 좋음을 증명합니다.


본 논문에서는 GAP가 원래의 제안 의도와는 다르게 이미지의 discrimitive region을 찾는 데 중요한 역할을 한다고 주장합니다. 또한 기존 Object Localizaton의 단점을 보완하여, end-to-end로 학습할 수 있고 단 한 번의 forward pass만을 수행해도 준수한 성능을 낼 수 있다고 주장합니다. 


# [2] 방법론

## Class Activation Map (CAM)
논문에서 제안한 GAP를 이용한 Localization 방법을 Class Activation Mapping이라 부릅니다. 먼저 전체적인 과정을 담은 그림을 아래에 첨부합니다.


<img src="/assets/figures/cam_overview.PNG" width="70%">


그림을 해석하자면 다음과 같습니다. 우선 분류를 위해 여러 개의 Convolutional layer를 통과합니다. 그리고 마지막 feature map에 GAP를 적용합니다. 각 채널마다 평균을 구해 하나의 노드로 표현한 것을 확인할 수 있습니다. 그리고 한 번의 forward pass를 적용하여 최종 클래스로 분류합니다. CAM은 forward pass에 사용된 가중치($w_k$)를 convolutional feature map에 가중합하여 도출하는 방식입니다.


수식으로 표현하면 다음와 같습니다. <br> $k$번째 feature map에 대해 $(x,y)$ 위치에서의 activation 값을 $f_k(x,y)$라 표현합니다. 그리고 해당 feature map에 GAP를 적용한 것을 $F_k$라 정의하고, 이는 $\sum_{(x,y)} f_k$로 표현할 수 있습니다(갯수만큼 나누어주는 것은 이후 연산에서 자연스럽게 약분되기 때문에 굳이 표시하지 않은 것 같습니다). 그렇다면 특정 클래스 $c$에 대해서, softmax의 입력으로 들어가는 값($S_c$)은 $\sum_k w_k^cF_k$가 될 것입니다. 아래에 수식을 정리하여 나열하겠습니다.

$$ S_c  = \sum_k w_k^c F_k $$

$$ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; = \sum_k w_k^c \sum_{x,y} f_k(x,y) $$

$$ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; = \sum_{x,y} \sum_k  w_k^c f_k(x,y) $$


이번에는 클래스 $c$에 대한 Class Activation Map을 $M_c$라 새로 정의합니다. 수식으로 나타내면 아래와 같습니다.

$$ M_c(x,y)=\sum_k w_k^c f_k(x,y) $$

이를 이용하여 다시 표현하면 $S_c = \sum_{x,y} M_c(x,y)$라는 식을 유도할 수 있습니다. 이 식은 **이미지가 $c$라는 클래스로 분류되는 데 중요한 역할을 하는 $(x,y)$ 좌표 위치에서의 활성화 정도**를 의미합니다. 이렇게 구해진 Class Activation Map을 원래 이미지 크기에 맞게 upsampling함으로써 원본 이미지에서 클래스 분류를 하는 데 중요한 부분을 시각화하여 보여줄 수 있습니다. 


# [3] 실험


위의 방법대로 실험한 결과는 아래와 같습니다.


<img src="/assets/figures/cam_result1.PNG" width="70%">


정답 클래스(briard, hen, barbell, bell cote)에 대해서는 Localization이 잘 수행된 것을 확인할 수 있는데요, 논문에서는 정답 클래스가 아닌 클래스에 대해서는 어떻게 CAM이 활성화되는지도 실험하였습니다. 그 결과는 아래와 같습니다.

<img src="/assets/figures/cam_result2.PNG" width="70%">


## Weakly-supervised Object Localization
본 논문에서 해결하고자 하는 목표는 Localization task에서 class level의 얕은 정보만으로 학습하여도 전체 정보로 학습한 것에 준하는 성능을 얻는 것입니다.


유명한 CNN 기반 모델인 AlexNet, VGGNet, GoogLeNet으로 실험을 준비하면서 논문 저자들은 다음과 같이 구조를 변경하였습니다.

  1. 기존 모델의 fc layer를 제거하고 GAP로 대체하였습니다.
  2. GAP 직전 convolutional layer, 즉 마지막 convolutional layer의 resolution(*mapping resolution*)이 클수록 Localization 성능이 향상됨을 확인하여 각 네트워크의 중간 convolutional 블록을 몇 개씩 제거하였습니다.

Classification과 Localization 두 가지 task에 대해 각각 실험을 진행하였는데, 각각에 대한 기본 세팅과 결과를 비교하겠습니다. 또한 GAP 대신 GMP를 사용한 모델도 비교를 위해 준비했습니다. 참고로 Classification에 대한 실험을 진행하는 이유는 Localization을 수행함에 있어 입력 이미지가 어떤 객체를 표현하는지 우선적으로 분류하는 것이 중요하기 때문입니다. Classification 성능이 떨어지는데 Localization 성능이 좋은 것을 기대하기는 힘들기 때문에 함께 실험을 진행하였습니다.


### 1) Classification
Classification에서는 변형을 가하지 않은 원래 모델과 Network in Network를 비교대상으로 설정하였습니다. 실험 결과는 아래와 같습니다. 참고로 AlexNet*-GAP 모델은 convolutional 블록 제거의 영향을 줄이기 위해 GAP 이전에 두 개의 convolutional layer를 추가한 모델입니다. 이는 원본 AlexNet과 성능이 유사함을 확인할 수 있습니다. 


Classification에서 GAP와 GMP의 유의미한 차이가 보이지는 않습니다. 핵심적인 특징이 분류에 결정적인 역할을 하기 때문에 GMP 역시 준수한 성능을 낸다고 해석해도 될 것 같습니다.

<img src="/assets/figures/cam_clsf.PNG" width="70%">


### 2) Localization
Localization에서는 원본 GoogLeNet, Network in Network와 CAM 대신 역전파를 사용한 버전을 비교대상으로 설정하였습니다. CAM을 적용한 모델은 Localization을 위해 만들어진 모델이 아니기 때문에 위에서 언급한 것과 같이 weakly-supervised 형태가 되겠습니다. 실험 결과는 아래와 같습니다.

<img src="/assets/figures/cam_local.PNG" width="70%">


이번 결과에서는 CAM 방식이 가장 좋은 성능을 보였습니다. 또한 GMP보다 GAP를 사용하는 것이 더 성능이 좋음을 확인할 수 있습니다.

## Deep Features for Generic Localization

논문에서는 다양한 카테고리를 지닌 데이터셋에 대해서도 fc layer 대신 GAP가 범용적으로 사용될 수 있는지를 실험하였습니다. 다양한 데이터셋에 대해 Classification을 수행한 실험 결과는 아래와 같습니다. GoogLeNet-GAP가 GoogLeNet보다 convolutional layer 수가 적음에도 불구하고 유사한 성능을 보이는 것을 확인할 수 있습니다.

<img src="/assets/figures/cam_dset.PNG" width="70%">


그리고 같은 데이터셋에 대해 CAM을 출력하면 아래와 같은 결과를 얻을 수 있습니다. 좋은 Localization 효과를 보입니다.

<img src="/assets/figures/cam_dset2.PNG" width="70%">


그 밖에도 fine-grained recognition이나 다양한 pattern을 발견하는 task에 대한 실험 역시 진행하였습니다. 개인적으로 재미있었던 부분은 Google StreetView 이미지 데이터 내에 존재하는 텍스트의 위치까지도 잘 인식한다는 것과 Visual Question Answering(VQA)에서도 좋은 성능을 보인다는 것이었습니다. 이 두 실험 결과에 대한 그림까지 첨부하고 다음으로 넘어가겠습니다.

<img src="/assets/figures/cam_text.PNG" width="70%">

<img src="/assets/figures/cam_vqa.PNG" width="70%">


## Visualizing Class-Specific Units

CNN 내 각 레이어의 convolutional unit은 시각적인 특징을 포착하는 역할을 합니다. 낮은 레벨에서는 질감 등의 특징, 높은 레벨에서는 물체나 장면 등의 특징을 포착하게 됩니다. 예를 들어 '강아지'라는 클래스를 표현하는 중요한 유닛은 강아지의 얼굴 형체나 털의 질감을 나타내는 유닛이 될 수 있겠습니다. 신경망이 깊어질수록 더 구분되는 특징(유닛)을 얻을 수 있는데, fc layer가 있는 경우 클래스에 대한 각 유닛의 중요도를 확인하는 것이 어려워진다고 합니다. 


정리하자면 하나의 클래스를 표현하는데 여러 개의 유닛(또는 sub-object)이 존재할 수 있고, 이러한 유닛을 <b>*class-specific unit*</b>이라 합니다. 역시 GAP를 이용하면 손쉽게 시각화가 가능하고, 이에 대한 실험 결과를 첨부하면서 실험에 대한 설명을 마치겠습니다.


<img src="/assets/figures/cam_cls.PNG" width="70%">



# [4] 마치며

딥러닝은 결과에 대한 해석이 어렵기 때문에 흔히 블랙박스라고도 불립니다. 연구를 넘어 실제 산업에 적용하기 위해서는 어떻게든 의미를 부여해야 하는 경우가 많을텐데, 이러한 측면에서 Class Activation Map이 갖는 의미는 굉장히 크다고 생각합니다.


연구실 세미나의 일환으로, 해당 논문에 대한 [리뷰 영상](https://youtu.be/KzpSM6erO6c)을 제작하였습니다. 필요하신 분은 참고해주시면 감사하겠습니다.


# [5] 참고자료
- [[Paper] Learning Deep Features for Discriminative Localization](https://arxiv.org/abs/1512.04150)
- [[Paper] Network in Network](https://arxiv.org/abs/1312.4400)