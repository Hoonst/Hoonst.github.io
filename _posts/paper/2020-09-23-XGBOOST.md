---

layout: article
title: "XGBOOST"
tags: paper_review
mathjax: true

---



# XGBoost: A Scalable Tree Boosting System

---

![image-20200923131019281](/Users/yoonhoonsang/Library/Application Support/typora-user-images/image-20200923131019281.png)

![image-20200923132623257](/Users/yoonhoonsang/Library/Application Support/typora-user-images/image-20200923132623257.png)



### Abstract

Tree Boosting은 성능이 좋아 다양한 분야에서, 다양한 목적으로 사용하고 있는 머신러닝 기법입니다. 본 논문에서는 XGBoost라는 확장 가능한 End-to-End 머신러닝 기법을 소개하고자 합니다. 

본 논문에선 주로

* Sparsity를 효과적으로 다룰 수 있는 알고리즘
* Weighted quantile sketch를 사용해 Tree learning을 근사

를 주요 소개 원리로 삼을 것입니다. 이에 더하여,

* Cache access patterns에 대한 인사이트
* Data Compression
* Sharding

등을 통해 확장 가능한 tree boosting system을 빌드업할 것입니다. XGBoost는 위와 같은 원리들로 수많은 데이터들을 마주하여도 기존보다 적은 리소스로 문제를 해결할 것입니다. 

### 1. Introduction

머신러닝과 데이터 기반 접근법은 많은 영역에서 중요도를 띄고 있습니다. 이런 모델들은 복잡한 데이터의 구조를 파악하고 광범위한 학습 시스템을 구축하고 있습니다. 

* Smart spam classifier
* Advertising System
* Fraud detection 등등



이런 머신러닝 기법들 중, Boosting도 한 자리를 꿰차고 있습니다. Boosting은 간단하게 설명하자면 다음과 같이 설명할 수 있습니다.

> 단일한 Predictor 대신, 다수의 Weak Predictor를 연속적으로 사용하여 Performance 향상을 노린다.

본 논문에서는 다양한 영역에서 사용할 수 있는 Tree Boosting, XGBoost를 설명하고자 합니다. XGBoost의 약력을 소개하자면,

* 2015년 Kaggle blog에서 공개한 Winning Solution 중 17/29개가 XGBoost (나머지 11개의 Solution은 Deep Neural Nets)
* 이 중, 8개는 XGBoost만 사용했고, 나머지는 XGBoost와 Neural Nets를 앙상블
* KDDcup 2015에서는 top 10 team들이 모두 XGBoost 사용
  인터뷰에 따르면 XGBoost를 사용하지 않은 앙상블이 XGBoost 단독으로 사용했을때보다 '아주 조금' 좋았다고 합니다. 즉 XGBoost가 짱짱맨이다.

이런 모습들을 봤을 때, XGBoost가 다양한 영역에서 SOTA 결과를 내고 있다고 합니다. 

* store sales prediction; 
* high energy physics event classification; 
* web text classification; 
* customer behavior prediction;
* motion detection; 
* ad click through rate prediction; 
* malware classification; 
* product categorization; 
* hazard risk prediction; 
* massive on- line course dropout rate prediction

위와 같은 '확장성'으로 인해, 물론 데이터 분석 및 머신러닝을 할 때 도메인 지식의 중요도는 매우 크지만, XGBoost를 활용할 시에는 그런 고려를 덜 해도 됩니다. 

**Scalability에 대한 강조를 매우 많이 하고 있습니다**

XGBoost의 확실하고 명확한 장점은 "Scalability"입니다. 이는 기존의 인기있는 솔루션들에 비하여 10배는 빠르고, 수십억개의 데이터를 Distributed 또는 메모리 제한적인 상황에서도 쉽게 활용할 수 있습니다. 이것이 가능한 이유는 크게 **System** 과 **Algorithmic** 최적화로 기인합니다. 

Innovation List:

* A Novel Tree Learning Algorithm: Sparse data 처리
* 이론적으로 검증된 Weighted Quantile Sketch $\Rightarrow$ Approximate tree learning
* Parallel and distributed computing
* Out-of core computation 



논문의 Contributions

* 



### 2. Tree Boosting in a Nutshell

XGBoost에 앞서, 본 섹션에선 Gradient Tree Boosting 알고리즘을 Recap하고 진행할 것입니다. 본 논문의 아이디어가 거기서 시작했기 때문이지요. 특히 이차 근사(Second Order Method)를 활용하는 생각은 Gradient Boosting의 저자, Friedman으로부터 나왔습니다. 우리는 여기에다가 목적함수에 정규화 식을 추가하는 작은 발전을 얹었을 뿐입니다. 

#### 2.1 Regularized Learning Objective

**여기서부터 Notation이 매우 난해합니다. Notation을 미리 정리하오니 헷갈리실때마다 다시 이곳을 살펴봐주시길 바랍니다.**

| Notation | Meaning                                        |      |      |
| -------- | ---------------------------------------------- | ---- | ---- |
| q        | 각 example을 leaf index로 뱉어내는 tree의 구조 |      |      |
| $T$      | Tree에 존재하는 leaf 갯수                      |      |      |
| $w_i$    | $i^{th}$ leaf의 점수                           |      |      |
| $f_k$    | K개의 additive functions                       |      |      |
|          |                                                |      |      |
|          |                                                |      |      |

m차원, 즉 m개의 feature를 갖는 n개의 데이터셋에 대하여 Tree 앙상블 모델은 K개의 additive functions를 통해 결과를 산출해냅니다. 

* 데이터 형태: $D = {(x_i,y_i)} (|D| = n,x_i ∈ R^m,y_i ∈ R)$

* Additive Functions: $\hat{y_i} =\phi(x_i)=􏰃\sum_{k=1}^{K}f_k(x_i), f_k ∈F$

* Space of Regression Trees
  $F=${${f(x)=w_{q(x)}}$} $(q:R^m →T,w∈R^T)$

여기서 

- $q$는 각 example을 leaf index로 뱉어내는 tree의 구조를 나타냅니다. 
- $T$는 tree에 존재하는 leaf의 갯수입니다. 
- $f_k$는 독립적인 하나의 트리 $q$ , 그리고 해당하는 tree의 leaf weight $w$를 말합니다. 

Decision Tree와 다르게, 각각의 regression tree는 leaf에 연속형 점수를 갖고 있으며, 이 점수인 $w_i$ 는 $i^{th}$ leaf의 점수를 나타냅니다. 

주어진 데이터가 있을 때, 먼저 tree의 decision rules를 통해 leaf에 classification을 한 뒤, 최종 예측을 각 leaf에 붙어 있는 점수들의 합산으로 나타냅니다. 

보통 머신러닝을 진행할 때, 손실 함수(Loss Function)을 구성합니다. 모델마다 손실 함수를 최소화 하는 방향으로 훈련을 해야하며, XGBoost에서는 다음과 같은 정규화된 손실 함수를 구성합니다.

$L(\phi) = 􏰃 \sum\limits_{i}l(\hat{y_i}, y_i) + 􏰃 \sum\limits_{k}Ω(f_k).   (2)$



**처음봤을 때, 본 Notation이 와닿지 않았었는데 그 이유는 $l(\hat{y_i}, y_i)$에서는 $i$ 에 대한 합산을 진행하지만, 뒤의 정규화 Term인 $Ω(f_k)$ 는 $k$ 에 대한 합산이기 때문입니다. sum을 진행하는 term은 다르지만 생각해보면 둘 다 같은 범위 내에서 연산이 이루어집니다.**

**첫번째 항 $l(\hat{y_i}, y_i)$ 은 $i$ 에 대한 항이죠. 위에서 $i$ 는 데이터의 index였습니다. 즉 데이터의 갯수인 $n$ 번 만큼 진행합니다.**

**두번째 항 $Ω(f_k)$ 는 $k$ 에 대한 항입니다. 이는 Tree들에 대한 정규화 과정인데 데이터들이 들어가는 Tree이기에 모든 index를 포함하고 있는 것입니다. 즉, 첫번째 항과 두번째 항의 Notation은 다르지만 Range는 같다고 할 수 있습니다.**

$l$: 미분 가능한 convex 손실 함수이다. 





#### 2.2 Gradient Tree Boosting

식 (2)번을 자세히 보면 정규화 부분에 "함수"를 파라미터로 갖기에, Euclidean Space 내에서 전통적인 최적화를 진행할 수 없다. 그리고 두 항 모두 numerical vector가 아니라 tree이기에 SGD 같은 절차를 따를 수 없습니다. 이를 해결하기 위하여 우리는 Boosting이 Additive Training이라는 부분을 Loss function에 반영해줍니다. 

$\hat y_i^{(t)}$ =$t^{th}$ iteration에서의 $i^{th}$ instance 예측값

우리의 목적식은 다음과 같이 구성할 수 있습니다. 

$L^{(t)} = 􏰃 l(y_i, y_i^{(t−1)} + f_t(x_i)) + Ω(f_t)$ ... (1)

$\Rightarrow$ (해석): Loss function $L^{(t)}$ 는 

* [정답 $y_i$] 와 

* [$t-1$ 시점의 예측값 $y_{i}^{(t-1)}$ 에, 현재 시점 $t$ 의 tree를 통해 예측한 $f_t(x_i)$ 를 더한 값] 의 Loss에
* 정규화 부분 $Ω(f_t)$ 를 최소화 해야합니다.

즉, 어떤 새로운 $f_t(x_i)$ 를 더해야 Loss를 최소로 만들 수 있을까의 문제입니다. 



$L(t) ≃􏰃[l(y_i,y^{(t−1)})+g_if_t(x_i)+\frac{1}{2}h_if_t(x_i)]+Ω(f_t)$ ... (2)

(1)번 식에 2차 근사식을 적용하게 되면 (2)번 식 처럼 표현할 수 있습니다. 

(2)번 식에서 $l(y_i, y^{(t-1)})$ 은 상수항이므로 이를 생략하여 더 간단한 식으로 만들 수 있습니다. 

$\tilde L^{(t)} = 􏰃[g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)] + Ω(f_t)$



$I_j = \{i|q(x_i)=j\}$ leaf $j$ 의 instance set



$\tilde{L}^{(t)} = \sum\limits_{i=1}^{n}[g_if_t(x_i) + \frac{1}{2}h_if_{t}^{2}(x_i)] + \gamma T + \frac{1}{2}\lambda\sum\limits_{j=1}^{T}w_{j}^2$ ... (3)

이제 정규화 표현식까지 원래 식으로 치환해서 나열하게 되면, 문제가 발생합니다. 앞의 부분은 $\sum\limits_{i=1}^{n}$ , $i$ 에서 $n$ 까지를 나타내며, 정규화 부분은 $\sum\limits_{j=1}^{T}$, $j$에서 $T$ 까지이므로 목적식을 간단하게 만들고 통일하기 위해선 둘 중에 하나의 $\sum$ 으로 통일해줘야 합니다. $\sum\limits_{j=1}^T$ 로 통일해보겠습니다. 

$=\sum\limits_{j=1}^{T}[(\sum\limits_{i\in I_j}g_i)w_j + \frac{1}{2}(\sum\limits_{i\in I_j}h_i + \lambda)w_{j}^2] + \gamma T$ ... (4)

$(\sum\limits_{i\in I_j}g_i)$ =  $j$번째 leaf에 포함된 instance set($I_j$)의 1차 미분 값들의 합

$(\sum\limits_{i\in I_j}h_i + \lambda)$ =$j$ 번째 leaf에 포함된 instance set($I_j$)의 2차 미분 값들의 합

해당 부분에서 Notation이 상당히 헷갈리고 난해합니다. 하지만 목적식 대상에 대한 본질을 고려하게 되면 이해가 될 것입니다. 그리고 (3)과 (4)를 대응해나가다 보면



고정된 $q(x)$에 대하여 $j$ leaf의 optimal weight $w_{j}^*$ 는

$w_j^*$ = $\frac{\sum\limits_{i \in I_j}g_i}{\sum\limits_{i\in I_j}h_i + \lambda}$

$\tilde{L}^{(t)}(q) = -\frac{1}{2}\sum\limits_{j=1}^T \frac{(\sum_{i \in I_j}g_i)^2}{\sum_{i\in I_j}h_i + \lambda} + \gamma T$

$L_{split} = \frac{1}{2}[\frac{(\sum_{i \in I_L}g_i)^2}{\sum_{i\in I_L}h_i + \lambda} + \frac{(\sum_{i \in I_R}g_i)^2}{\sum_{i\in I_R}h_i + \lambda} - \frac{(\sum_{i \in I}g_i)^2}{\sum_{i\in I}h_i + \lambda}] - \gamma$ ... (7)







#### 2.3 Shrinkage and Column Subsampling

XGBoost에는 이전 섹션에서 얘기해왔던 정규화 목적식 이외에도 Overfitting을 피하기 위한 두 가지 기술이 존재합니다. 

* Shrinkage $\Rightarrow$ Friedman이 소개
* Subsampling



### 3. Split Finding Algorithms

#### 3.1 Basic Exact Greedy Algorithm

Tree 학습에 있어 중요한 문제는 Tree Split을 어떻게 최적으로 나눌 것이냐 입니다. 이를 위해 Split finding algorithm은 모든 경우의 수를 살펴보게 되는데 이를 **exact greedy algorithm** 이라고 합니다. 해당 알고리즘은 아래 이미지와 같이 이루어집니다.

![image-20200924160725514](/Users/yoonhoonsang/Library/Application Support/typora-user-images/image-20200924160725514.png)

하지만 모든 경우의 수를 살펴보는 것은 데이터 양이 매우 크면 상당한 부하를 요구합니다. 이를 방지할 수 있는 효과적인 방법은 feature 값을 정렬하고 정렬된 순서대로 데이터를 탐색하여 미분 값을 찾아나가는 것입니다. 

#### 3.2 Approximate Algorithm

**Exact greedy algorithm** 은 모든 경우의 수를 탐색하기에 당연히 최적의 값을 찾기에 용이합니다. 파라미터 서치를 할 때도 모든 경우를 다 시도해보는 것이 정답을 찾는 것인 부분과 유사합니다. 하지만 아쉽게도 데이터가 지나치게 크면, Memory에 전부 반영할 수 없습니다. 이는 Distributed Setting에서도 마찬가지입니다. 따라서, 최적의 값을 찾기가 힘들때 사용하는 '근사' 알고리즘을 사용하고자 합니다. 

근사 알고리즘은 다음과 같이 이루어집니다. 

![image-20200924163852782](/Users/yoonhoonsang/Library/Application Support/typora-user-images/image-20200924163852782.png)

요약하여 순서를 설명하자면 다음과 같습니다. 

1. Feature 분포의 quantile을 이용하여 Candidate Splitting Points를 구합니다. (자세한 사항은 3.3에서 다룹니다)
2. 1에서 구한 Candidate Splitting Points를 기반으로 Continuous features를 Bucket splits로 나누어, statistics(G-1차미분 / H-2차미분)을 취합하고 제안된 Point로 나누었을 때의 Statistics를 기반으로 최적의 분기점을 찾습니다.

Proposal를 *언제* 하느냐에 따라, Split의 값(variant)이 달라지곤 합니다. 

* Global Variant: Tree를 구성하기 시작하는 시점에서 Proposal을 구축하고, 모든 단계에서 같은 proposal을 사용합니다. 따라서 local variant와 다르게 한 번만 계산하기에 proposal step이 적습니다. 계산 횟수는 적지만, 더 많은 proposal을 제시하는데 그 이유는 각 분기마다 후보들이 Refined 되지 않아서입니다. 
* Local Variant: 매 분기(split)마다 새로운 Proposal을 합니다. 이때 분기 이후, Local Proposal은 candidate들을 지속적으로 refine하므로 깊은 tree에 어울릴 수 있습니다. 
* Proposal 수: Global Variant < Local Variant
* Candidate 수: Global Variant > Local Variant
* Proposal이 더 많으면 Candidate도 더 많아야 하는거 아냐?

#### 3.3 Weighted Quantile Sketch

Approximate algorithm의 가장 중요한 단계는 Candidate split points를 제안하는 것입니다. 주로 feature의 분위수로 candidate를 정하면 데이터에 고르게 결정되었습니다. 

수식으로 나타내보면
$D_k = {(x_{1k}, h_1), (x_{2k}, h_2) ... (x_{nk}, h_n)}$ 는 $k$-th 번째의 Feature 값과 이차 미분 값을 담고 있음을 의미합니다. 여기에 Ranking을 정의하면

$r_k(z) = \frac{1}{\sum_{(x,h) \in D_k}h} \sum\limits_{(x, h) \in D_k, x<z }h$로 정의됩니다. 이는 

feature 값이 z보다 작은 x의 2차 미분 값 / $D_k$의 2차 미분 값의 합을 의미합니다. 

#### 3.4 Sparsity-aware Split Finding

### 4. System Design

#### 4.1 Column Block for Parallel Learning

​	Tree Learning에서 가장 시간 소요가 많이 드는 부분은 데이터를 정렬하는 것입니다. 이 부분의 비용을 감소시키기 위해 **block**이라는 in-memory unit에 데이터를 저장하는 것을 제안합니다. Block에 포함된 데이터는 각 column이 해당하는 feature로 정렬되어 있는 Compressed Column(CSC) format으로 저장됩니다. 이 데이터 꼴은 훈련 전에 단 한번만 구성되면 되고, 이후의 iteration에서 재사용될 수 있습니다. 

​	Exact greedy algorithm에서는 전체 데이터를 하나의 block에 넣고 Linearly, 즉 일일이 미리 정렬된 데이터를 살펴보면서 split을 할 지점을 탐색합니다. 

<img src="/Users/yoonhoonsang/Library/Application Support/typora-user-images/image-20200925184244101.png" alt="image-20200925184244101" style="zoom:33%;" />

Block 구조는 approximate 알고리즘에도 도움이 됩니다. 이 때는 Multiple Block이 사용되고

#### 4.2 Cache-aware Access

### 5. Related Works

### 6. End to End Evaluations

#### 6.1 System Implementation

#### 6.2 Dataset and Setup

#### 6.3 Classification

#### 6.4 Learning to Rank

#### 6.5 Out-of-core Experiment

#### 6.6 Distributed Experiment

### 7. Conclusion















