---
layout: post
title: "DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning"
description: "Min Du, Feifei Li, Guineng Zheng, Vivek Srikumar (ACM CCS 2017)"
date: 2020-11-13
categories: paper
tags: [review, code, deeplearning, anomaly detection]
image: 
---

# [1] 아이디어 제안 배경

## 시스템 로그(System Log)

컴퓨터에서 시스템 로그는 시스템의 상태에 대한 기록을 의미합니다. 시스템 상에서 오류가 발생했을 때 시스템 로그는 발생 원인과 발생 위치에 대한 충분한 정보를 제공합니다. 또한 모든 컴퓨터 시스템에 존재하기 때문에 데이터 수집에 대한 접근성이 좋습니다.


## System Anomaly Detection

시간이 흐를수록 시스템은 점점 복잡해지고, 이에 따라 발생하는 이상현상(anomaly)의 위험성은 증가합니다. 이상현상의 종류 역시 다양해지죠. 이전에도 시스템 이상현상은 계속 발생했기 때문에 이를 방지하기 위한 방법론이 존재했지만, 시스템의 복잡성이 증가함에 따라 전통적인 방법론의 효과가 점점 감소하게 되었습니다. 기존의 방법론 중 두 개 정도만 아래에 가볍게 소개합니다.

- PCA 기반 방법론: 로그를 세션 단위로 구분한 다음 PCA를 적용하여 이상현상을 보이는 세션(벡터) 탐지

- Invariant mining 기반 방법론: 대부분의 세션 벡터에서 변하지 않는(내재적인) 특징을 추출하고, 이 특징을 만족하지 않는 벡터 탐지

  
이러한 방법론들은 특정한 상황에 대해서는 효과적일 지도 모르나, <b>실시간 상황(online fashion)</b>에서나 <b>기존에 없던 새로운 유형의 이상현상</b>에 대해 탐지하는 것이 불가능합니다. 또한 일반적으로 시스템 로그가 서로다른 여러 개의 스레드에서 기록되거나 병렬적으로(concurrently) 기록되는데, 이전의 방법론들은 하나의 task에 대한 이상현상만을 탐지할 수 밖에 없다는 한계가 있었습니다.


본 논문에서 제안하는 방법론인 DeepLog는 위의 문제를 해결하기 위해 시스템 로그를 "자연어 시퀀스"처럼 다루어 패턴을 효과적으로 탐지합니다. DeepLog의 특징을 아래에 간략하게 정리하겠습니다. 각각에 대한 자세한 내용은 뒤에서 이야기하도록 하겠습니다.

- 실시간 시스템 로그 이상현상 탐지 가능
- LSTM 모델을 사용하여 시스템 로그 이상현상을 효과적으로 탐지
- 사용자의 이상현상 진단을 위한 workflow 모델 제공
- 병렬 task나 다른 시퀀스에 대한 로그를 효과적으로 분리할 수 있음
- 새로운 이상패턴에 대해 지속적으로 모델 업데이트 가능


# [2] 방법론
방법론 소개에 앞서 미리 말씀드리자면, 논문에서 사용하는 시스템 로그 데이터는 "공격받지 않았음"을 가정합니다. 즉, 외부의 공격자에 의해 의도적으로 이상현상이 발생하는 상황(DoS 등)은 가정하지 않고 정상 시스템 실행 프로세스에서 발생하는 이상패턴만을 감지한다는 뜻입니다.

## Model Architecture
DeepLog의 전체적인 구조는 아래 그림과 같습니다.

<img src="/assets/figures/log_model.png" width="70%">

위 모델은 크게 세 가지로 구분할 수 있습니다.
1. Log key anomaly detection 모델
2. Parameter value anomaly detection 모델
3. Workflow 모델(탐지된 이상치를 진단하는 목적)

각각에 대해 아래에서 설명하도록 하겠습니다.


## 데이터 전처리: Log Parsing
그 전에 먼저 사용하는 데이터에 대해 알 필요가 있습니다. 시스템 로그 데이터는 엄격한 문법(구조)을 지닌 데이터입니다. 이 로그를 log entry라고 칭하며, 이를 log key와 parameter value로 분리해야 합니다. 

```python 
# 시스템 로그 예시 (log entry)
print(f"{service_name} 서비스를 {num_port}번 포트에서 실행하였습니다.")
```

위의 시스템 로그 예시에서 log key는 ```* 서비스를 *번 포트에서 실행하였습니다.``` 입니다. 시스템 로그 메시지의 종류라고 이해하시면 될 것 같습니다. 그리고 ```service_name```과 ```num_port```를 parameter value라고 합니다. Log key에 적용될 수 있는 세부 값인 셈입니다. 따라서 하나의 log key에는 다양한 parameter value가 존재하고, 시스템 실행 상황에 따라 다른 value가 출력될 수 있는 것입니다. 논문에서 든 예시를 아래의 표로 첨부합니다.

<img src="/assets/figures/log_entry.png" width="70%">


DeepLog의 또다른 장점으로는 기존의 방법론이 log key 위주로만 이상치 탐지를 진행했던 것과 다르게 time stamp와 parameter value까지 고려하여 좋은 성능을 낸다는 것입니다. 

## Training Stage
DeepLog는 다음과 같은 학습 단계를 거칩니다. 기본적으로 정상 프로세스의 로그 데이터로 학습하고, 로그를 key와 parameter value 벡터로 변환합니다.

### ① Log Key Anomaly Detection 모델 학습
시스템 로그에서 parsing된 log key 시퀀스는 특정 시스템이 실행되는 과정에 대한 정보를 담고 있습니다. 이 단계에서는 고유한 log key를 각각의 클래스로 설정하여 언어 모델을 구축합니다. 다시 말하면, ${h }$시점 이전부터 현재 시점까지의 로그 시퀀스가 주어졌을 때, 다음에 등장할 log key를 예측하는 multi-class classifier를 학습시키는 것입니다. 학습 단계에서는 ${ h}$를 3으로 설정하였다고 합니다. 모델은 LSTM을 사용하였고, LSTM 모델의 효용을 증명하기 위해 비교군으로 삼은 모델은 N-gram 기반의 모델입니다. 



### ② Parameter Value Anomaly Detection 모델 학습

모델이 log key를 정상으로 예측하여도, parameter value에 따라 이상치가 되는 경우가 존재합니다. 따라서 위에서는 log key에 대해서만 이상현상을 탐지했다면, 각 log key 내에 존재하는 parameter value에 대해서도 이상현상을 탐지할 필요가 있는 것입니다.


단순한 방법으로는 모든 parameter value 시퀀스를 하나의 matrix로 표현하여 이상한 값을 찾아내는 것입니다.

<img src="/assets/figures/log_entry.png" width="70%">


이전에 보여드렸던 표를 다시 가져왔습니다. 표에 나타난 log key는 총 3개이고 각 2개, 2개, 1개의 parameter value를 갖고 있습니다. 그렇다면 matrix의 첫 번째 행은 ${t_1 }$ 시점의 parameter value를 갖고 있는 형태로 나타낼 수 있습니다. 다만 각 log key마다 갖고 있는 parameter value의 개수가 다르기 때문에 정리하면 아래와 같은 형태로 표현됩니다.

```python
# parameter value matrix
[
    [t_1 - t_0, file1Id,      None,  None,      None],
    [     None,    None, t_2 - t_1,  0.61,      None],
    [     None,    None,      None,  None, t_3 - t_2],
    ...
]
```

그러나 위의 방법은 matrix가 매우 sparse하게 형성되며 실시간 탐지를 위해서도 효율적인 방법이 아닙니다. 따라서 DeepLog에서는 parameter value sequence를 <b>시계열 데이터</b>로 간주하여 문제를 해결합니다. 간단한 예를 들자면 ${ k_2 }$는 시간에 따라 parameter의 값이 변하기 때문에 이를 시계열 데이터로 이용할 수 있습니다. 시계열 예측에도 역시 LSTM을 사용하여 일정 MSE를 초과하는 값을 이상현상으로 간주합니다.

### ③ Online Update

모델의 지속적인 업데이트를 위해 중요한 것은 기존 모델이 정확하게 예측하지 못하는 새로운 유형의 이상현상을 새로 학습할 수 있어야 한다는 점입니다. 아래와 같은 잘못된 예측 상황이 존재할 수 있습니다.

- 모델은 다음에 정상 데이터가 등장할 것이라 예측했지만, 이상치가 등장한 경우 (False Positive로 정의)

이 경우에 대해 모델은 해당 패턴을 추가적으로 학습하게 되며, 유사한 상황이 다시 등장한다면 이상치가 발생했던 상황을 감안하여 확률적인 예측을 할 수 있습니다.


## Detection Stage

입력값은 먼저 log key에 대한 anomaly detection이 수행됩니다. 입력값의 형태는 학습 단계와 동일하며 다음에 등장할 log key(여러 개가 존재할 수 있음)가 정상 데이터인지 이상 데이터인지를 예측합니다. 


조금 더 구체적으로 설명하자면 다음과 같습니다. ${ t}$시점에 등장하는 log key와 모델이 ${t }$시점에 등장할 것으로 기대하는 ${g }$개의 후보(높은 확률 순)를 비교합니다. ${ t}$시점의 log key가 ${ g}$개의 후보 중에 존재한다면 해당 log key는 정상으로 분류됩니다.


이후 log key 기준에서 정상으로 예측된 데이터는 parameter value anomaly detection을 한 번 더 진행합니다(log key에서 이상치로 탐지되면 그것은 바로 이상치라고 간주합니다). 여기서 이상치로 판단되는 값은 log key에서는 정상이나 parameter value가 이상치라고 예측되는 값입니다. 이 두 가지 anomaly detection 모델을 모두 통과해야만 정상 데이터라고 할 수 있습니다. 어느 단계에서라도 이상치로 판단되는 경우에는 학습된 workflow model의 도움을 받아, 사용자가 어떤 상황에서 이상현상이 발생하였는지를 파악할 수 있습니다.


## Workflow Model 구축

시스템 로그는 어떠한 업무를 수행하는 데 사용되는 함수를 순서대로 보여줍니다. 따라서 이상현상이 발생한 경로를 파악하는 데 효과적이라는 이유로 특정 업무에 대한 실행 경로를 파악하는 workflow model을 구축하는 것은 중요합니다. 그러나 많은 이전의 방법론에서는 여러 업무에 대한 workflow를 효과적으로 구축하지 못하는 한계가 있었습니다.


실제로 시스템 로그는 우리가 기대하는 것처럼 업무 별로 깔끔하게 구분되어 나타나지 않습니다. 서로 다른 업무에서 동일한 log key가 등장하는 경우도 있고, 하나의 업무에서 병렬적으로 스레드를 처리하는 경우도 있기 때문입니다. 따라서 로그 파일 내 존재하는 여러 업무 별로 log entry를 구분하는 것은 중요한 이슈입니다.


논문에서 소개한 log entry 구분 방법에 대해 아래에 가볍게만 설명하도록 하겠습니다. 논문에 예시를 들어 잘 설명하기 때문에 궁금하신 분들은 참고하시면 되겠습니다.

- DeepLog를 이용한 log entry 분리 <br>
다음에 등장하는 시스템 로그를 예측하기 위해서는 이전 시점의 로그를 참조해야 합니다. 다만 참조하는 시점이 짧을수록 어떠한 context인지 파악하기 어렵기 때문에 참조하는 시점을 길게 조정함으로써 이를 판단합니다. 또한 여러 업무가 진행되는지, 아니면 하나의 업무 내에서 병렬적으로 프로세스가 진행되는지를 구분하기 위해서 발생하는 로그의 진행 양상을 파악합니다.

- Density-based clustering을 이용한 분리 <br>
하나의 업무에서 등장하는 여러 log key는 함께 등장하는 빈도가 높을 것입니다. 같은 논리로 서로다른 업무에서 각각 등장하는 log key들은 함께 등장할 확률이 적을 것입니다. 이를 기반으로 co-occurance matrix를 만들어서 함께 발생할 확률이 적은(거리가 먼) log key들을 분리하는 방법입니다.



# [3] 코드

DeepLog 모델의 코드는 [이 곳](https://github.com/wuyifan18/DeepLog)을 많이 참조하였습니다. 또한 전체 pipeline이 아닌, log anomaly detection 모델만을 이용하여 HDFS 로그 데이터에 대한 이상치 탐지를 수행해보았음을 미리 밝힙니다. 설치가 필요한 라이브러리는 ```pytorch-lightning==1.0.5``` 입니다.

## 1. Import libraries
```python
import os
import sys
import time

import torch
import torch.nn as nn
import torch.optim as optim
import pytorch_lightning as pl

from tqdm import tqdm
from torch.utils.data import TensorDataset, DataLoader
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger
```

## 2. Set hyperparameters
```python
class Hyperparameters:
    """ Hyperparameters for DeepLog """

    seed = 711

    gpus = 1
    epoch = 200
    batch_size = 2048
    lr = 0.001

    input_size = 1
    num_classes = 28
    num_layers = 2
    hidden_size = 64
    window_size = 10

    # for prediction
    num_candidates = 9
```

## 3. Log key anomaly detection model
일정 시점 간격의 로그 시퀀스를 LSTM 모델에 적용하는 모델입니다. 손실함수는 CrossEntropy를 사용합니다.

```python
class DeepLog(pl.LightningModule):
    """Log Anomaly Detection Model

    :param input_size: input data size
    :param hidden_size: lstm hidden size
    :param window_size: past information to help predict the next log key
    :param num_layers: number of lstm layer
    :param num_classes: number of log keys

    :param lr: learning rate
    """

    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        window_size: int,
        num_layers: int,
        num_classes: int,
        lr: float,
    ):
        super(DeepLog, self).__init__()
        self.save_hyperparameters()

        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)

        self.criterion = nn.CrossEntropyLoss()

    def forward(self, x):
        h0 = torch.zeros(
            self.hparams.num_layers, x.size(0), self.hparams.hidden_size
        ).to(self.device)
        c0 = torch.zeros(
            self.hparams.num_layers, x.size(0), self.hparams.hidden_size
        ).to(self.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

    def configure_optimizers(self):
        return optim.Adam(self.parameters(), lr=self.hparams.lr)

    def training_step(self, batch, batch_idx):
        seq, label = batch
        seq = (
            seq.clone()
            .detach()
            .view(-1, self.hparams.window_size, self.hparams.input_size)
            .to(self.device)
        )

        output = self(seq)
        loss = self.criterion(output, label)
        return {"loss": loss}

    def training_epoch_end(self, outputs):
        train_loss_mean = torch.stack([x["loss"] for x in outputs]).mean()
        self.log("trn_loss", train_loss_mean)
```

## 4. Train model
로그 시퀀스 데이터를 구성하는 함수를 사용하여 DataLoader를 선언하고, 학습을 시작합니다.

```python
def generate(name, window_size, num_classes):
    """ Structure

    root/
      └── data/
          ├── hdfs_train
          ├── hdfs_test_abnormal
          └── hdfs_test_normal
      └── your_code.ipynb
    """
    num_sessions = 0
    inputs = []
    outputs = []
    with open("data/" + name, "r") as f:
        for line in f.readlines():
            num_sessions += 1
            line = tuple(map(lambda n: n - 1, map(int, line.strip().split())))
            for i in range(len(line) - window_size):
                inputs.append(line[i : i + window_size])
                outputs.append(line[i + window_size])
    print("Number of sessions({}): {}".format(name, num_classes))
    print("Number of seqs({}): {}".format(name, len(inputs)))
    dataset = TensorDataset(
        torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs)
    )
    return dataset

# Load hyperparameters
hparams = Hyperparameters()

# Fix seed for reproducibility
pl.seed_everything(hparams.seed)

# Set dataset and dataloader
train_dset = generate("hdfs_train", hparams.window_size, hparams.num_classes)
train_loader = DataLoader(
    train_dset, batch_size=hparams.batch_size, shuffle=True, pin_memory=True
)

# Set model
model = DeepLog(
    input_size=hparams.input_size,
    hidden_size=hparams.hidden_size,
    window_size=hparams.window_size,
    num_layers=hparams.num_layers,
    num_classes=hparams.num_classes,
    lr=hparams.lr,
)

# Set training config
early_stopping = EarlyStopping(
    monitor="trn_loss", patience=3, strict=False, verbose=True, mode="min"
)
logger = TensorBoardLogger("logs", name="deeplog")
checkpoint_callback = ModelCheckpoint(
    monitor="trn_loss",
    dirpath="deeplog/",
    filename="checkpoint-{epoch:02d}-{trn_loss:.2f}",
    save_top_k=3,
    mode="min",
)

# Set trainer
trainer = pl.Trainer(
    gpus=hparams.gpus,
    deterministic=True,
    logger=logger,
    callbacks=[early_stopping, checkpoint_callback],
    max_epochs=hparams.epoch,
)

# Train model
trainer.fit(model, train_loader)
```

저는 train loss에 대한 early stop 옵션을 추가하였고, 132에폭까지 수행 후 수렴하여 학습이 종료되었습니다.

<img src="/assets/figures/log_train.png" width="70%">


## 5. Predict anomalies
정상 데이터에 대한 testset과 이상 데이터가 포함된 testset에 대해 각각 loader를 구성하였습니다. 또한 False Positive, False Negative를 구하여 Precision/Recall/F1 Score를 출력하였습니다.


```python
def generate_pred(name, window_size):
    hdfs = set()
    # hdfs = [] # for using full dataset
    with open("data/" + name, "r") as f:
        for ln in f.readlines():
            ln = list(map(lambda n: n - 1, map(int, ln.strip().split())))
            ln = ln + [-1] * (window_size + 1 - len(ln))
            hdfs.add(tuple(ln))
            # hdfs.append(tuple(ln))
    print("Number of sessions({}): {}".format(name, len(hdfs)))
    return hdfs
    
device = DeepLog.device

bestmodel = DeepLog.load_from_checkpoint(checkpoint_callback.best_model_path)

print("model_path: {}".format(checkpoint_callback.best_model_path))
test_normal_loader = generate_pred("hdfs_test_normal", hparams.window_size)
test_abnormal_loader = generate_pred("hdfs_test_abnormal", hparams.window_size)

TP = 0
FP = 0

# Test the model
start_time = time.time()
with torch.no_grad():
    for line in tqdm(test_normal_loader):
        for i in range(len(line) - hparams.window_size):
            seq = line[i : i + hparams.window_size]
            label = line[i + hparams.window_size]
            seq = (
                torch.tensor(seq, dtype=torch.float).view(
                    -1, hparams.window_size, hparams.input_size
                )
            )
            label = torch.tensor(label).view(-1) 
            output = bestmodel(seq)
            predicted = torch.argsort(output, 1)[0][-hparams.num_candidates :]
            if label not in predicted:
                FP += 1
                break
                
with torch.no_grad():
    for line in tqdm(test_abnormal_loader):
        for i in range(len(line) - hparams.window_size):
            seq = line[i : i + hparams.window_size]
            label = line[i + hparams.window_size]
            seq = (
                torch.tensor(seq, dtype=torch.float).view(
                    -1, hparams.window_size, hparams.input_size
                )
            )
            label = torch.tensor(label).view(-1)
            output = bestmodel(seq)
            predicted = torch.argsort(output, 1)[0][-hparams.num_candidates :]
            if label not in predicted:
                TP += 1
                break
                
elapsed_time = time.time() - start_time
print("elapsed_time: {:.3f}s".format(elapsed_time))

# Compute precision, recall and F1-measure
FN = len(test_abnormal_loader) - TP
P = 100 * TP / (TP + FP)
R = 100 * TP / (TP + FN)
F1 = 2 * P * R / (P + R)
print(
    "false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%".format(
        FP, FN, P, R, F1
    )
)
print("Finished Predicting")
```

결과를 확인하면 아래와 같습니다. Parameter value anomaly detection 없이 Log key anomaly detection에 대해서만 수행한 성능도 준수하게 나오는 것을 확인할 수 있습니다.


<img src="/assets/figures/log_result.png" width="70%">



# [4] 마치며
시스템 로그에 대한 이상치탐지를 수행하면서 실제 사용자 레벨까지 고려한 점이 인상깊은 논문이었습니다. 단순히 LSTM을 새로 적용한 것 뿐만이 아닌 전체적인 파이프라인을 설계하는 과정이 쉽지 않았을 것이라 생각합니다. 다만 읽는 입장에서 논문의 목차 구성이 복잡하게 되어 있다는 느낌을 받았습니다. 자신의 아이디어를 효과적으로 전달하는 방법에 대해 한 번 더 고민을 하게 되는 시간이었습니다.


# [5] 참고자료
- [[Paper] DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning](https://www.cs.utah.edu/~lifeifei/papers/deeplog.pdf)
- [[Youtube] DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning](https://www.youtube.com/watch?v=At19CBGpbMI&t=236s)
- [[Code] DeepLog](https://github.com/wuyifan18/DeepLog)