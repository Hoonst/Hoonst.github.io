---
layout: post
title: "Unsupervised Data Augmentation for Consistency Training"
description: "Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, Quoc V.Le (NIPS 2020)"
date: 2020-12-13
categories: paper
tags: [review, deeplearning, code, data augmentation]
image: 
---

# [1] 아이디어 제안 배경

## Semi-supervised Learning

딥러닝을 공부하는 많은 사람들은 어떻게 하면 현실 세계에서도 잘 적용할 수 있을지를 함께 고민합니다. 하지만 연구에서 사용하는 벤치마크 데이터셋처럼 많은 양에 label까지 존재하는 데이터는 찾아보기 힘든 경우가 대다수입니다. Semi-supervised learning은 이 문제를 해결하기 위해 등장한 방법론으로, label이 존재하는 데이터가 적을 때 label이 없는 데이터를 활용하여 문제 해결 능력을 향상시키는 방법을 제시합니다. 

### Consistency Training

최근에는 **consistency training** 기법이 많이 사용되고 있습니다. Consistency training이란, label이 존재하지 않는 데이터의 입력 또는 은닉상태(hidden state)에 noise가 추가되어도 강건한 예측을 할 수 있도록 학습하는 방법론입니다. 즉, unlabeled 데이터와 noise가 추가된 unlabeled 데이터의 예측 분포가 유사하도록 제약을 만드는 것입니다. Noise는 대표적으로 Gaussian noise가 적용됩니다. 적은 labeled 데이터로 학습한 모델이 unlabeled 데이터를 예측할 경우 발생하는 불확실성을 보완하기 위한 방법인 것 같습니다.


본 논문에서는 강건한 예측을 위해 삽입하는 noise, 즉 augmentation에 대해 탐구하고 unlabeled 데이터에 augmentation을 적용하여 label이 적은 현실적인 상황에서도 잘 사용할 수 있는 방법론인 Unsupervised Data Augmentation(UDA)를 소개합니다. 방법론 부분에서 본격적으로 설명하겠지만, 핵심적인 효과는 아래와 같습니다.

- 지도학습에서 주로 사용되는 뛰어난(state-of-the-art) augmentation 방법론들이 consistency training에서도 훌륭한 noise 공급원이 될 수 있음
- UDA를 적용하는 것이 모든 label을 사용하는 purely supervised learning 성능과 유사하거나 더 뛰어날 수 있음
- UDA는 전이학습(transfer learning)과도 잘 어울림(ImageNet, BERT 등)
- UDA의 성능에 대한 이론적인 증명이 가능

> Consistency training(unlabeled 데이터에서도 augmentation을 적용)에서 뛰어난 augmentation 기법의 사용을 강조하기 위해 UDA라는 이름을 붙였다고 합니다.

## Data Augmentation

먼저 data augmentation이 적용되는 상황에 대해 가볍게 짚고 넘어가겠습니다. 아래에서 등장하는 notation의 정의를 미리 적어두고 시작하겠습니다.

- $x$: 입력 데이터
- $y^\ast$: Ground Truth
- $\theta$: 파라미터
- $p_\theta(y\mid x)$: Supervised 모델의 예측분포
- $p_L$: label이 존재하는 데이터의 분포
- $p_U$: label이 존재하지 않는 데이터의 분포
- $f^\ast$: 찾고자 하는 이상적인 classifier


### 1) Supervised Data Augmentation
지도학습 상황에서의 data augmentation은 label을 변화시키지 않는 수준에서 데이터에 변형을 가하는 방법입니다. 즉, $x$라는 데이터가 있을 때 $q(\hat{x} \mid x)$라는 augmentation을 적용하는 것입니다. 분포에 대한 식으로 나타내면 아래와 같습니다.

$$ \hat{x} \sim q(\hat{x} \mid x) $$

$x$와 $\hat{x}$는 반드시 같은 label을 갖고 있어야 하기 때문에, 최적화 시 augmentation이 적용된 데이터에 대해서도 negative log-likelihood를 최소화하도록 학습합니다. 결국 지도학습에서의 augmentation은 새로운 데이터를 추가해 주는 작업이기 때문에 주어진 표본에 대한 inductive bias를 더해주는 역할을 하게 됩니다.


그러나 이러한 augmentation은 *"케이크에 체리를 얹는 수준(cherry on the cake)"* 의 효과밖에 갖지 못한다는 비판이 있습니다. 현실적으로 label의 수가 적은 경우가 굉장히 많은데, 방법론이 적은 데이터를 대상으로만 적용되어 왔다는 이유 때문입니다. 따라서 이 단점을 극복하기 위해 (label이 존재하지 않는)데이터를 많이 확보할 수 있는 준지도학습(semi-supervised learning) 분야로 범위가 확장되었습니다. Consistency training이 대표적인 사례가 되겠습니다.


### 2) Unsupervised Data Augmentation
글의 첫 부분에도 언급을 했지만, 준지도학습 기반의 consistency training에서는 unlabeled 데이터에 대해 augmentation을 수행합니다. 큰 흐름은 아래와 같습니다. 이 과정을 거치면 모델이 noise에 덜 민감한 방향으로 학습을 하게 됩니다. 

1. Label이 없는 입력 데이터 $x$에 대해 출력 분포 $p_\theta(y\mid x)$를 계산합니다.
2. 입력값 또는 은닉상태(hidden state)에 약간의 노이즈를 추가한 출력 분포 $p_\theta(y\mid x, \epsilon)$를 계산합니다.
3. 두 분포 $p_\theta(y\mid x)$와 $p_\theta(y\mid x, \epsilon)$의 divergence metric(여기서는 Cross Entropy)을 최소화합니다.


UDA가 기존 consistency training과 다른 점은 사용한 augmentation 기법입니다. 이전의 연구에서는 주로 Gaussian noise 같이 약한 수준의 noise를 적용하였습니다. 그러나 UDA에서는 강한 수준의 augmentation이 준지도학습 하에서 훨씬 좋은 성능을 낼 수 있다고 주장합니다.


# [2] 방법론
본 논문에서는 Vision Task와 NLP Task에서의 효과를 모두 검증합니다. 그러나 본 포스팅에서는 **Vision Task** 위주로 설명드리겠습니다. NLP Task의 관점에서 UDA에 대한 설명을 듣고 싶으시면 [이 블로그](https://joungheekim.github.io/2020/12/13/code-review/)를 참고하시면 되겠습니다.



## Architecture

UDA의 핵심인 loss는 아래와 같이 구성됩니다. Consistency loss에 따라 unlabeled 데이터에 대한 robustness를 확보함과 동시에 labeled 데이터의 정보 역시 unlabeled 데이터로 전달할 수 있습니다.

<img src="/assets/figures/uda_arch.PNG" width="70%">

수식으로 표현하면 아래와 같습니다. Notation의 정의도 다시 적어두겠습니다.

$$ min_\theta \mathcal{J}(\theta) = \mathbb{E}_{x_1 \sim p_L(x)} \left[ -\log p_\theta (f^\ast (x_1) \mid x_1) \right] + \lambda \mathbb{E}_{x_2 \sim p_U} \mathbb{E}_{\hat{x} \sim q(\hat{x} \mid x_2)} \left[ CE(p_{\tilde{\theta}} (y \mid x_2) \parallel p_\theta (y\mid \hat{x})) \right]  $$

> 논문의 이전 버전에서는 divergence metric으로 KL Divergence를 사용한 것 같습니다. 그러나 KLD를 최소화하는 것이나 CE를 최소화하는 것이나 본질적으로는 동일합니다.

- $x$: 입력 데이터
- $y^\ast$: Ground Truth
- $\theta$: 파라미터
- $p_\theta(y\mid x)$: Supervised 모델의 예측분포
- $p_{\tilde \theta}(y\mid x)$: 현재 파라미터를 고정시킨 상태에서의 예측분포
- $p_\theta(y\mid \hat{x})$: Augmentation이 적용된 데이터의 예측분포
- $p_L$: label이 존재하는 데이터의 분포
- $p_U$: label이 존재하지 않는 데이터의 분포
- $f^\ast$: 찾고자 하는 이상적인 classifier
- $\lambda$: Supervised loss와 Unsupervised loss의 정도를 조절


Unlabeled 데이터의 예측분포를 계산하는 식에서 현재 파라미터를 고정하는 부분이 등장하는데, 이는 unlabeled 데이터에 대한 모델의 예측값을 고정시킨 상태에서 augmented unlabeled 데이터의 예측분포를 labeled 데이터의 예측분포에 가깝게 만들기 위함입니다. 또한 하나의 배치에서 unsupervised consistency loss를 계산하는 데 더 많은 데이터를 할당합니다. 뒤의 ablation study에서도 나오겠지만, unlabeled 데이터를 많이 확보하는 것이 labeled 데이터를 많이 확보하는 것보다 성능 향상에 효과적이기 때문입니다.

## Advanced Data Augmentation: RandAugment

Vision task의 UDA에서 사용하는 augmentation 기법은 RandAugment입니다. RandAugment는 Python Image Library(PIL)에서 제공하는 모든 이미지 처리 기법을 균일하게 샘플링하여 사용하는 기법입니다. 굉장히 단순하여 쉽게 적용할 수 있습니다. 


<img src="/assets/figures/uda_randaug.PNG" width="70%">

> 논문에서 사용한 RandAugment 선택지는 Invert, Cutout, Sharpness, AutoContrast, Posterize, ShearX, TranslateX, TranslateY, ShearY, Rotate, Equalize, Contrast, Color, Solarize, Brightness의 선택지가 존재합니다.

이전 버전에서는 AutoAugment를 사용했는데, 몇 가지 이유로 인해 기법을 바꾸게 되었습니다. AutoAugment는 가장 좋은 augmentation 기법을 찾기 위해 PIL에서 제공하는 방법들에 대해 강화학습 기반의 탐색을 진행합니다. 그렇기 때문에 시간이 굉장히 오래 걸린다는 단점이 있었습니다.


UDA에서는 augmentation 방법 외에 몇 가지 기법을 더 적용하여 성능 하락을 방지하였습니다. 아래에서 소개하도록 하겠습니다.

### Additional: Confidence-based masking
Unlabeled 데이터를 다룰 때, 학습된 supervised 모델이 unlabeled 데이터를 자신있게 예측하지 못한다면(예측값이 실제값과 다를 확률이 높다면) 학습이 제대로 되지 않을 수 있습니다. 따라서 unlabeled 데이터에 대한 예측값의 확률이 threshold $\beta$보다 높은 경우에 대해서만 consistency training을 진행합니다. 


### Additional: Sharpening Predictions
또한 예측값에 대한 entropy가 낮을수록(특정 label을 더 자신있게 예측하도록) 좋은 성능을 낸다는 이전 연구를 참고하여, 예측값의 분포를 더 뾰족하게 만드는 기법을 적용합니다. 이는 softmax 확률을 계산할 때 temperature term($\tau$)을 추가하여 조정할 수 있습니다. 


위의 confidence-based masking과 결합하여 하나의 미니배치($B$)를 대상으로 consistency loss에 대한 수식을 표현하면 아래와 같습니다.

$$ {1 \over \vert B\vert} \sum_{x \in B} I(max_{y\prime} p_{\tilde{\theta}}(y\prime \mid x) > \beta) CE(p_{\tilde{\theta}}^{sharp} (y\mid x) \parallel p_\theta (y\mid \hat{x}) ) $$


$$ p_{\tilde{\theta}}^{sharp} (y\mid x) = { exp(z_y/\tau) \over {\sum_{y\prime} exp(z_{y\prime}/\tau)}} $$

### Additional: Domain-relevance Data Filtering

본 논문에서는 많은 unlabeled 데이터를 확보하기 위해 out-of-domain unlabeled 데이터를 활용하고자 했습니다. 그러나 in-domain 데이터와 함께 사용될 경우 클래스 분포의 불일치가 발생하기 때문에 직접 사용할 경우 성능 저하가 발생합니다. 따라서 아래와 같은 방법으로 out-of-domain 데이터의 일부를 찾아내어 사용합니다.

1. In-domain 데이터로 학습한 모델로 out-of-domain 데이터를 inference 합니다.
2. Inference 결과 중 confidence가 높은 데이터만을 골라서 사용합니다.



## Theoretical Analysis

UDA의 효과를 이론적으로 검증하기 위해서는 먼저 augmentation에 대한 세 가지 가정이 필요합니다.

**① In-domain augmentation** <br>
$x \sim p_U(x)$에서 augmentation을 적용한 $\hat{x} \sim q(\hat{x} \mid x)$는 $p_U(\hat{x})>0$의 값을 가져야 합니다.


**② Label-preserving augmentation** <br>
최적의 classifier $f^\ast$에 대해, $f^\ast(x) = f^\ast(\hat{x})$를 만족해야 합니다.


**③ Reversible augmentation** <br>
Augmentation 연산은 역으로도 수행될 수 있어야 합니다. 아래와 같은 방식입니다.

$$ if \;\; q(\hat{x} \mid x)>0, \;\; then \;\; q(x\mid \hat{x})>0 $$


### 직관적인 이해
먼저 이론에 대한 직관적인 이해를 바탕으로 설명드리겠습니다. 모든 데이터 샘플을 각각 노드로  하는 그래프 $G_{PU}$를 가정합니다. 그래프의 edge는 위의 가정 ③을 만족하는 경우 이어지게 됩니다. 그렇다면 같은 label을 갖는 노드는 서로 edge로 연결되어 있을 것이고, 서로 다른 label을 갖는 노드는 연결되어 있지 않을 것입니다. 따라서 $N$개의 클래스가 존재하고, augmentation을 통해 같은 클래스 내의 모든 노드를 탐색할 수 있다고 가정한다면 $N$개의 component(또는 sub-graph)가 존재할 것입니다. 만약 같은 클래스를 갖는 두 노드가 augmentation으로 이어질 수 없는 경우가 있다면 $N$개 이상의 component가 존재할 것입니다. 하지만 적어도 각 component 내의 노드들은 augmentation을 통해 서로 도달할 수 있습니다. 아래의 그림은 클래스가 2개이고 component가 3개인 그래프의 예시입니다.

<img src="/assets/figures/uda_comp.PNG" width="70%">


그런데 supervised data augmentation 상황에서는 label이 존재하는 노드와 직접적으로 연결되어 있는 이웃 노드까지밖에 탐색할 수 없습니다. 즉 augmentation의 범위가 제한되어 있다는 뜻입니다. 반면, unsupervised data augmentation에서는 **component 내의 모든 노드에 도달할 수 있다**는 장점이 있습니다. 이것이 UDA가 잘 작동하는 이유 중 하나입니다. 하나의 component에 대해 supervised와 unsupervised 방법론을 간단히 그림으로 비교하면 아래와 같습니다.

<img src="/assets/figures/uda_proof.PNG" width="70%">


다음으로 넘어가서, 이러한 방법을 사용하여 최적의 분류기를 찾기 위해서는 각 component마다 적어도 하나의 labeled 데이터가 존재해야 합니다. 즉, **최소 component 개수의 하한은 최적의 분류기를 학습하는 데 필요한 labeled 데이터의 최소 개수와 같습니다**. 간단히 예를 들면 아래와 같습니다.

- 5개의 클래스가 있는 데이터
- 최적의 분류기를 학습하기 위해 최소 5개의 labeled 데이터가 필요함
- Component 개수는 가장 적을 때가 5개, 상황에 따라 5개 이상으로 구성될 수 있음


그런데 여기서 짚고 넘어가야 할 점은 **component의 개수가 사실은 augmentation quality와 직접적으로 연관이 있다는 것**입니다. 이유는 다음과 같습니다. Gaussian noise 같은 약한 수준의 augmentation은 원 데이터와 비교하여 큰 변화가 없기 때문에 탐색할 수 있는 주변 노드의 범위 역시 줄어들게 됩니다. 이는 하나의 component가 적은 수의 노드만을 갖게 됨을 의미하며, 전체 component의 개수는 많아질 것입니다.


반면 label을 변화시키지 않는 범위 내에서 다양한(또는 강한 수준의) augmentation을 적용한다면 보다 많은 노드를 하나의 component로 포함시킬 수 있을 것입니다. 따라서 그래프의 연결성이 좋아져 전체 component의 개수는 적어집니다. 그렇다면 지금까지의 논리를 기반으로 아래와 같은 결론을 내릴 수 있습니다. 


A. 하나의 component는 적어도 하나의 labeled 데이터를 포함해야 한다. <br>
B. 좋은 augmentation을 사용하면 탐색 범위가 넓어져 그래프의 연결성이 좋아진다. <br>
C. 그래프의 연결성이 좋아진다는 것은 전체 component의 개수가 줄어듦을 의미한다.<br>
D. A에 근거하여, **component가 적을수록 필요로 하는 labeled 데이터의 개수는 적어진다**. <br>
E. 이는 UDA에서 ideal augmentation을 도입하는 핵심 근거이다.


위의 내용들을 아래의 그림으로 한 번에 표현할 수 있습니다. 한 문장으로 표현하자면 "UDA는 labeled 데이터와 직접적으로 연결되지 않은 노드에 대한 탐색을 할 수 있는 것이 장점이고, ideal augmentation을 사용하여 component의 개수를 줄임으로써 labeled 데이터를 덜 사용하여도 좋은 성능을 낸다."가 될 것 같습니다.


<img src="/assets/figures/uda_graph.PNG" width="70%">


# [3] 실험

Vision task에 대한 실험에서는 적은 양의 데이터셋인 CIFAR-10과 SVHN, 그리고 많은 양의 데이터셋인 ImageNet에 대해 실험을 진행하였습니다.

## 1. Correlation between Supervised and Semi-supervised Performances
아래 표는 지도학습에서의 data augmentation 효과가 준지도학습에서의 data augmentation에서도 정비례하게 적용되는지를 보이는 실험입니다. 비교군인 Crop&flip과 Cutout에 비교하여 supervised 실험과 semi-supervised 실험에서 동일한 추세를 보이는 것을 확인할 수 있습니다.

<img src="/assets/figures/uda_table1.PNG" width="70%">


## 2. Algorithm Comparison on Vision Semi-supervised Learning Benchmarks
아래의 실험에서는 기존의 준지도학습 알고리즘과 비교하여 UDA의 뛰어난 성능을 검증합니다.

### 1) Vary the size of labeled data
먼저 Wide-ResNet-28-2 모델을 기준으로 label이 존재하는 데이터의 개수에 따른 성능 변화를 측정하였습니다. 비교군은 대표적인 준지도학습 기반 방법론인 Virtual Adversarial Training(VAT)과 MixMatch입니다. UDA가 모든 상황에서 뛰어난 성능을 기록하고 있고, 특히 VAT와는 큰 차이를 보입니다. 


<img src="/assets/figures/uda_label_size.PNG" width="70%">

### 2) Vary model architecture
다양한 모델에 대해서도 검증을 하였습니다. 같은 모델을 기준으로 UDA가 가장 좋은 성능을 보이고, 표에는 나오지 않았지만 labeled 데이터가 10배나 많은 fully-supervised 모델보다 좋은 성능을 보인다고 언급합니다.

<img src="/assets/figures/uda_table3.PNG" width="70%">

## 3. Scalability Test on the ImageNet Dataset
CIFAR-10과 SVHN은 비교적 작은 데이터셋에 속합니다. UDA가 큰 스케일의 데이터셋에도 잘 동작하는 것을 증명하기 위해 ImageNet 데이터를 대상으로 실험을 진행하였습니다. 10%의 데이터만 사용하는 경우와 모든 데이터를 사용하는 경우에 대한 실험을 진행하였고, 모든 데이터를 사용하는 경우에 대해서는 위에서 언급한 domain-relevance data filtering을 적용한 JFT 데이터셋 1.3M개를 unsupervised 데이터로 활용하였습니다. 결과는 아래와 같습니다.

<img src="/assets/figures/uda_table5.PNG" width="70%">


## 4. Ablation Studies
마지막으로 논문에서 추가로 진행한 실험 몇 개에 대해서만 소개하고 넘어가겠습니다.

### 1) Training Signal Annealing for Low-data Regime
준지도학습에서는 label이 존재하는 데이터와 존재하는 데이터의 개수가 굉장히 많이 차이나는 경우가 많습니다. 그래서 종종 labeled 데이터에 오버피팅되는 현상이 발생합니다. 따라서 본 논문에서는 TSA라는 기법을 도입하여 labeled 데이터의 학습을 조절합니다. TSA의 역할을 직관적으로 설명하자면, 쉬운 데이터는 학습하지 않고 건너뛰도록 합니다. 학습 단계에서 특정 클래스에 대한 예측 확률이 일정 threshold를 넘어서면 너무 쉬운 예측이라 판단하고 해당 데이터를 제거해버리는 것입니다. 


TSA의 종류는 아래 세 가지가 있는데요, 가장 오른쪽의 exp schedule에 대해서 간단한 예시를 들고 넘어가겠습니다. 풀고자 하는 문제가 쉽다고 가정한다면 확률값이 대체로 높게 나오기 때문에 exp 그래프의 낮은 threshold에 모두 걸려버리게 됩니다. Threshold의 기준이 천천히 증가하기 때문에 많은 쉬운 데이터가 제거되고, 결과적으로는 오버피팅을 어느 정도 방지하게 되는 것입니다. 반대로 log schedule에서는 풀고자 하는 문제가 어려울 경우 적합할 것입니다.

<img src="/assets/figures/uda_tsa.PNG" width="70%">


### 2) The Importance of Having More Unsupervised Examples

논문에서는 labeled 데이터보다 unlabeled 데이터를 많이 준비하는 것이 훨씬 중요하다고 주장합니다. 이를 실험으로 검증한 내용이 아래와 같습니다.

<img src="/assets/figures/uda_uns.PNG" width="70%">


### 3) The Number of Possible Transformations

논문의 RandAugment에서는 총 15개의 transformation 선택지를 사용하는데, 선택지의 개수에 따른 성능 비교도 측정하였습니다. 많을수록 효과가 좋습니다.

<img src="/assets/figures/uda_rnd.PNG" width="70%">


# [4] 코드
UDA의 효과를 확인해보기 위해 CIFAR-10 데이터셋을 사용하여 코드를 구현해보았습니다. 저자 코드가 존재하긴 하지만 아이디어가 간단한 편이라 혼자 구현해 보았습니다. 전체 코드는 [여기](https://github.com/youngerous/uda)에서 확인하실 수 있습니다. 본 글에서는 코드의 일부들만 예시로 가져와 설명하도록 하겠습니다.

## 데이터 로드
CIFAR-10 데이터셋은 다양한 이미지와 각각에 대응되는 10개의 클래스(label)의 쌍으로 구성된 데이터입니다. 
학습 데이터 40000개, 검증 데이터 10000개, 그리고 평가 데이터 10000개로 구성할 수 있습니다.
준지도학습 상황을 만들어주기 위해 데이터셋을 조금 변형하여 구성하였습니다. 
```uda=True```로 설정할 경우 적은 수의 labeled 데이터와 나머지 unlabeled 데이터를 활용할 수 있습니다. 


```python 
class CIFAR10(Dataset):
    """
    Custom CIFAR-10 dataset for semi-supervised setting.
    :param path: root path of CIFAR-10 dataset
    :param mode: train/val/test
    :param labeled: if false, only return unlabeled data
    :param uda: whether to apply uda
    :param data_batch: number of data batches of CIFAR-10 (default: 5)
    :param num_labeled: number of labeled data to use (must-use in uda)
    """

    def __init__(
        self,
        path: str,
        mode: str,
        labeled: bool,
        uda: bool,
        data_batch: int = 5,
        num_labeled: int = None,
    ):
        super(CIFAR10, self).__init__()
        assert mode in ["train", "val", "test"], "You must choose train/val/test"
        self.labeled = labeled
        self.uda = uda

        self.images = None
        self.labels = []

        if mode in ["train", "val"]:
            # aggregate data batches
            for batch in range(data_batch):
                data = None
                with open(os.path.join(path, f"data_batch_{batch+1}"), "rb") as fo:
                    data = pickle.load(fo, encoding="bytes")
                img = data[b"data"]
                img = img.reshape(len(img), 32, 32, 3)
                label = data[b"labels"]

                try:
                    self.images = np.concatenate((self.images, img), axis=0)
                except ValueError:  ## at first batch
                    self.images = img
                self.labels.extend(label)

            if not uda:
                assert (
                    labeled
                ), "You cannot use unlabeled data when not using UDA. Please set labeled==True."

                # convert data type and split train/val
                n_train = 40000
                self.images = self.images[:n_train] if mode == "train" else self.images[n_train:]
                self.labels = (
                    torch.LongTensor(self.labels)[:n_train]
                    if mode == "train"
                    else torch.LongTensor(self.labels)[n_train:]
                )
                assert len(self.images) == len(self.labels), "data/label length mismatch"

                # You can set the number of labeled data to use
                if mode == "train" and num_labeled is not None:
                    assert num_labeled <= n_train, f"labeled data cannot be over {n_train}."
                    self.images = self.images[:num_labeled]
                    self.labels = self.labels[:num_labeled]

            else:  # uda
                n_train, n_val = 40000, 10000
                assert num_labeled is not None, "You must set num_labeled value in UDA."
                assert num_labeled <= n_train, f"labeled data cannot be over {n_train}."

                if mode == "train":
                    self.images = (
                        self.images[:num_labeled] if labeled else self.images[num_labeled:-n_val]
                    )
                    self.labels = (
                        self.labels[:num_labeled] if labeled else self.labels[num_labeled:-n_val]
                    )
                else:
                    self.images = self.images[n_train:]
                    self.labels = self.labels[n_train:]
                self.labels = torch.LongTensor(self.labels)

        else:  # test
            data = None
            with open(os.path.join(path, "test_batch"), "rb") as fo:
                data = pickle.load(fo, encoding="bytes")
            self.images = data[b"data"]
            self.images = self.images.reshape(len(self.images), 32, 32, 3)
            self.labels = torch.LongTensor(data[b"labels"])

        print(f"[{mode.upper()}] Number of data: {len(self.images)}")
        print(f" ** Current Options ** UDA: {self.uda} / Labeled: {self.labeled}")
```

## TSA annealing
TSA Annealing은 log/linear/exp 세 개의 선택지를 만들어 적은 labeled data에 오버피팅되는 현상을 어느정도 방지합니다. 관련 코드는 아래와 같이 작성하였습니다.
```python 
def get_tsa_threshold(self):
    K = self.num_classes
    T = self.tsa_max_step

    alpha = None
    if self.tsa == "exp":
        alpha = np.exp((self.global_step / T - 1) * 5)
    elif self.tsa == "linear":
        alpha = self.global_step / T
    else:
        alpha = 1 - np.exp(-(self.global_step / T) * 5)
    threshold = alpha * (1 - 1 / K) + 1 / K
    return threshold
```


## RandAugment
UDA의 consistency loss를 구성하기 위해서는 augmentation을 포함하여 여러 연산 과정이 추가됩니다. 따라서 end-to-end 구조의 모델을 학습시키기 위해서는 많은 시간이 필요합니다. 제 구현에서는 end-to-end로 모델을 구성하였으나, 논문의 저자들은 학습 속도를 빠르게 하기 위해 augmentation(RandAugment)이 적용된 이미지를 미리 생성하여 따로 저장해 두었다고 합니다. 파이토치로 구현한 기존 라이브러리가 존재하여 이를 사용하였습니다.
```python
def augmentation(self, img, randaugment=False):
        if randaugment:
            img = Image.fromarray(img)
            return transforms.Compose(
                [
                    RandAugment(),
                    transforms.ToTensor(),
                    transforms.RandomCrop(32),
                    transforms.RandomHorizontalFlip(),
                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
                ]
            )(img)
        else:
            return transforms.Compose(
                [
                    transforms.ToTensor(),
                    transforms.RandomCrop(32),
                    transforms.RandomHorizontalFlip(),
                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
                ]
            )(img)
```

## 결과
모델 학습 후 테스트 데이터셋에 대해 성능을 측정한 결과는 아래와 같습니다. 생각보다는 성능 향상이 크게 일어나지는 않았는데요, 학습을 몇 번 돌려보면서 하이퍼파라미터에 민감한 방법론이 아닐까 생각했습니다. Random seed나 모델의 크기를 키우고, 기타 uda 관련 하이퍼파라미터를 더 탐색한다면 논문의 성능에 더 가까운 성능 향상이 이루어지지 않을까 싶습니다. 

|     Model      | Number of labeled examples | Augmentation | Top-1 Accuracy |
| :------------: | :------------------------: | :----------: | :------------: |
|   ResNet-50    |           40000            | Crop & Filp  |      73%       |
|   ResNet-50    |            4000            | Crop & Flip  |      48%       |
| ResNet-50(UDA) |            4000            | RandAugment  |      50%       |


# [5] 마치며

간단하면서도 굉장히 뛰어난 성능을 갖고 있는 논문입니다. 논문은 작년에 올라왔지만 학회에 accept된 것은 올해입니다. 그 사이에도 엄청나게 인용이 된 것을 보면 학계에 파급력이 큰 방법론인 것 같습니다. 하이퍼파라미터 탐색이나 end-to-end 학습과 관련된 이슈가 존재하는 것 같지만 이를 기반으로 많은 새 연구가 등장할 것 같아 기대가 되는 논문입니다.


# [6] 참고자료

- [[Paper] Unsupervised Data Augmentation for Consistency Training](https://arxiv.org/abs/1904.12848)
- [[YouTube] Semi-supervised Learning - Generative Models](https://www.youtube.com/watch?v=v0GfbdvL8DY&list=PLetSlH8YjIfWMdw9AuLR5ybkVvGcoG2EW&index=34)
- [[YouTube] Paper Review - MixMatch: A Holistic Approach to Semi-Supervised Learning](https://www.youtube.com/watch?v=nSJP7bn2D1U)
- [[YouTube] PR-189: Unsupervised Data Augmentation for Consistency Training](https://www.youtube.com/watch?v=YiKn93Ud4dA&t=1890s)